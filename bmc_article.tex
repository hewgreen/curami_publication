%% BioMed_Central_Tex_Template_v1.06
%%                                      %
%  bmc_article.tex            ver: 1.06 %
%                                       %

%%IMPORTANT: do not delete the first line of this template
%%It must be present to enable the BMC Submission system to
%%recognise this template!!

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                     %%
%%  LaTeX template for BioMed Central  %%
%%     journal article submissions     %%
%%                                     %%
%%          <8 June 2012>              %%
%%                                     %%
%%                                     %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                                 %%
%% For instructions on how to fill out this Tex template           %%
%% document please refer to Readme.html and the instructions for   %%
%% authors page on the biomed central website                      %%
%% http://www.biomedcentral.com/info/authors/                      %%
%%                                                                 %%
%% Please do not use \input{...} to include other tex files.       %%
%% Submit your LaTeX manuscript as one .tex document.              %%
%%                                                                 %%
%% All additional figures and files should be attached             %%
%% separately and not embedded in the \TeX\ document itself.       %%
%%                                                                 %%
%% BioMed Central currently use the MikTex distribution of         %%
%% TeX for Windows) of TeX and LaTeX.  This is available from      %%
%% http://www.miktex.org                                           %%
%%                                                                 %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% additional documentclass options:
%  [doublespacing]
%  [linenumbers]   - put the line numbers on margins

%%% loading packages, author definitions

%\documentclass[twocolumn]{bmcart}% uncomment this for twocolumn layout and comment line below
\documentclass{bmcart}

%%% Load packages
%\usepackage{amsthm,amsmath}
%\RequirePackage{natbib}
%\RequirePackage[authoryear]{natbib}% uncomment this for author-year bibliography
%\RequirePackage{hyperref}
\usepackage[utf8]{inputenc} %unicode support
%\usepackage[applemac]{inputenc} %applemac support if unicode package fails
%\usepackage[latin1]{inputenc} %UNIX support if unicode package fails
\usepackage{siunitx}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                             %%
%%  If you wish to display your graphics for   %%
%%  your own use using includegraphic or       %%
%%  includegraphics, then comment out the      %%
%%  following two lines of code.               %%
%%  NB: These line *must* be included when     %%
%%  submitting to BMC.                         %%
%%  All figure files must be submitted as      %%
%%  separate graphics through the BMC          %%
%%  submission process, not included in the    %%
%%  submitted article.                         %%
%%                                             %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\def\includegraphic{}
\def\includegraphics{}



%%% Put your definitions there:
\startlocaldefs
\endlocaldefs


%%% Begin ...
\begin{document}

%%% Start of article front matter
\begin{frontmatter}

\begin{fmbox}
\dochead{Research}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Enter the title of your article here     %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{Curami: An Assisted Attribute Curation Tool for the BioSamples Database.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Enter the authors here                   %%
%%                                          %%
%% Specify information, if available,       %%
%% in the form:                             %%
%%   <key>={<id1>,<id2>}                    %%
%%   <key>=                                 %%
%% Comment or delete the keys which are     %%
%% not used. Repeat \author command as much %%
%% as required.                             %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\author[
   addressref={aff1},                   % id's of addresses, e.g. {aff1,aff2}
   corref={aff1},                       % id of corresponding address, if any
   noteref={n1},                        % id's of article notes, if any
   email={hewgreen@ebi.co.uk}   % email address
]{\inits{}\fnm{Matthew} \snm{Green}}
 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Enter the authors' addresses here        %%
%%                                          %%
%% Repeat \address commands as much as      %%
%% required.                                %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\address[id=aff1]{%
  \orgname{European Bioinformatics Institute, European Molecular Biology Laboratory (EMBL)},
  \street{Wellcome Trust Genome Campus},
  \postcode{CB10 1SD}
  \city{Cambridge},
  \cny{UK}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Enter short notes here                   %%
%%                                          %%
%% Short notes will be after addresses      %%
%% on first page.                           %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{artnotes}
%\note{Sample of title note}     % note to the article
\note[id=n1]{Equal contributor} % note, connected to author
\end{artnotes}

\end{fmbox}% comment this for two column layout

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% The Abstract begins here                 %%
%%                                          %%
%% Please refer to the Instructions for     %%
%% authors on http://www.biomedcentral.com  %%
%% and include the section headings         %%
%% accordingly for your article type.       %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{abstractbox}

\begin{abstract} % abstract
\parttitle{First part title} %if any
Text for this section.

\parttitle{Second part title} %if any
Text for this section.
\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% The keywords begin here                  %%
%%                                          %%
%% Put each keyword in separate \kwd{}.     %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{keyword}
\kwd{metadata}
\kwd{biosamples}
\kwd{assisted curation}
\kwd{data quality}
\end{keyword}

% MSC classifications codes, if any
%\begin{keyword}[class=AMS]
%\kwd[Primary ]{}
%\kwd{}
%\kwd[; secondary ]{}
%\end{keyword}

\end{abstractbox}
%
%\end{fmbox}% uncomment this for twcolumn layout

\end{frontmatter}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%  The Main Article
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Background}

Architects of biological databases are forced to decide which trade offs to make in order to best balance the data consumer's downstream requirements, a data contributors input effort versus the value added benefits and the project's available resources. Whilst inexplicit validation and pliable data schema lower the barrier to initial data submission, this practice results in unstructured data that is difficult to reuse without incurring high curation costs. Many tools have been built which aim to improve data quality whilst minimising incurred financial and time costs. These tools broadly operate either pre-data submission (validation) or post-data submission (curation) [REF NEEDED]. Within these two strategies, the tools are spread on a scale between fully automated or fully manual. Often increased manual effort correlates with increased data value and diminishing throughput. Therefore, a tool should be designed to suit the requirements of the resource \cite{goble2008data}. Thankfully, there are applications that succesfully leverage the benefits of automated data assessment and combine this with expert manual curation to measurably increase the efficiency of manual curation efforts \cite{salgado2012myminer, salimi2006biocurator, szostak2015construction}.

The BioSamples database at the European Bioinformatics Institute (EBI) is a metadata repository for all biological samples used to generate datasets across the EBI \cite{gostev2011biosample, faulconbridge2013updates}. The database consists of more than 4.5 million sample records which each contain a unique BioSamples identifier. Many records also have links to the sample's derived data in external databases, relationships to other samples (derived from, child of etc.) and sample metadata expressed as key value pairs (note that keys are hereinafter referred to as attributes). As the database provides a single point of entry to metadata from a wide range of scientific domains and technologies, BioSamples allows users to create ad hoc fields that are not predefined. Whilst this increases utility and flexibility for submitters, the dataset suffers from redundancy and inconsistency. For example there are 22 different attributes that contain longitudes. Although BioSamples mitigates this problem by providing elastic search with ontology expansion, the samples returned may not necessarily be findable, accessible, interoperable and reusable, the universal targets defined as the FAIR principles \cite{wilkinson2016fair}. A snapshot of the dataset containing 4,790,415 sample records (taken on the 5th January 2018) was used for initial analysis. These samples contained 29,751 unique attributes used conjointly 45,275,314 times, giving a mean average of 9.45 attributes per sample record. The redundancy and inconsistency within the large number of attributes in the BioSamples database prompted the creation of the assisted-curation tool described herein.

The overarching goal was to provide a tool that facilitates the reduction of redundancy and inconsistency of the attributes in the BioSamples database, ultimately to reduce the total number of attributes in the database without loosing information. In order to achieve this, we aimed to identify pairs of attributes that were semantically similar enough to merge and to further identify the correct polarity of the merging. Although these aims differ from recent work to identify more generally topically related attributes in the Gene Expression Omnibus (GEO) \cite{edgar2002gene, barrett2012ncbi}, the strategy the authors employ highlighted some key challenges to solving this problem \cite{hu2017cleaning}. Whilst GEO encourages data submitters to conform to the Minimum Information About a Microarray Experiment (MIAME) guidelines \cite{brazma2001minimum}, similarly to BioSamples, the lack of a controlled vocabulary leads to the usage of different terms to represent the same concept. The authors developed a clustering methodology to group attributes that covered similar concepts and in doing so aim to separate curation activities into more manageable chunks. Unfortunately, applying clustering methodologies to data with heavily biased distributions leads to biased results which impedes semantic understanding. Furthermore as is the case for BioSamples, the majority of metadata submissions come from relatively few pipelines which often impose their own validation, recommendations and guidelines which leads to further clustering bias and renders frequency of term usage a less definitive predictive metric.

%(longitude, longitude (raw), geographic location (latitude and longitude), Geographic location (latitude, longitude), geographic location (longitude), geographical location (longitude and longitude), longitude.dd, latitude and longitude, latitude longitude, Longitude (W), GPS Longitude W, Longitudinal Minutes, Longitudinal Degrees, source longitude latitude elev(m), Geographic location (latitude and longitude), Dec longitude, sequencing location longitude, library preparation location longitude, birth location longitude, Longitude Start and Longitude End, CH1903 LV03 Longitude Y)

\section*{Methods}

Source code and application documentation is available for inspection and reuse at \textit{https://github.com/EBIBioSamples/curami}.

\subsection*{Pairing Rationale}

Curami aims to both identify erroneous attributes in the dataset and find a suitable a replacement string. Both of these functions are required in order to successfully curate the sample record. In order to identify an erroneous attribute's replacement, we assume that the dataset contains a more suitable attribute most of the time. Hence, we are trying to identify attribute synonyms within the dataset and elect a preferred term to replace the others. This strategy aims to reduce the total number of attributes whilst maintaining meaningful semantic differentiation.

\subsection*{Overview of Data and Work Flow}

During initialization, each sample record is requested via the BioSamples Application Programming Interface (API) and parsed into four input files. A CSV list of unique attributes and their frequency of usage, a CSV list of sample records (including the BioSamples ID and the attributes the sample contains), a CSV list of attribute pairs that co-occur within a sample record at least once with the frequency of the co-occurrence and a JSON file with unique values and their frequency of use for each unique attribute. The second step of initialisation uses these four files to create a network using the Python package networkX \cite{networkx} which is exported as a .gexf for later use by the co-occurrences analysis script. This graph contains nodes representing individual attributes and weighted edges with co-occurrence can also be instantly visualised using Gephi \cite{bastian2009gephi} and explored using various inbuilt force-directed layout algorithms \cite{jacomy2014forceatlas2} (see Figure \cite{fig:gephi}).

Curami has a tiered modular design to aid fungibility of the code (see figure \ref{fig:workflow}). The 29,751 attributes expands into 885,092,250 potential unique pairs, excluding self-matches. Therefore, the initial tier (high throughput pairing) filters this high number of potential pairs into a smaller number that is able to undergo more rigorous similarity computation. This layer is designed to be optimised for throughput and therefore may only rely on a low computational burden for pair selection. As such the selected pairs at this stage are most likely not mergeable (synonyms).

Once attribute pairs have been filtered to a more manageable number the second tier (pairwise analysis) can be performed. In this tier a range of analysis modules calculate various similarity features for each pair. The modular design is critical to encourage future development of new orthogonal approaches. One example of an additional module could be pairwise ontology comparisons. At the time of publication, Curami has four modules for feature calculation. These are mismatch typing, lexical similarity, sample co-occurrence and value similarity. These modules calculate 13 core features outlined in table \ref{table:features}. This analysis dataset is stored in a graph database using Neo4J.

The workflow thus far has been automated and can therefore be triggered at regular intervals to keep up to date. The user interface is a flask application capable of navigating the attribute pairs, reviewing analysis and making curation decisions. For each pair the user can choose not to merge, merge the least frequently used attribute into the more popular of the pair or to merge in the reverse direction. This simple interface takes inspiration from gamification concept in web app design by facilitating quick decision making and showing individual curators their comparative impact statistics. These decisions are also captured in the graph database and form the basis of both export of curation objects directly to the BioSamples API and training data for later machine learning and tuning.

\subsection*{Leveraging Machine Learning by Design}

The workflow has the capacity to leverage manual curation effort

\subsection*{}
%The Initially, to reduce this number for feature analysis pairs with a Levenshtein distance is lower than 0.8 are removed \cite{levenshtein1966binary}. 35,699 pairs were above this threshold (lexically matched pairs) and underwent further analysis.

\subsection*{Co-occurrence Network}

Co-occurrence refers to attributes that are used together within the same sample. By counting co-occurrence we can quantify a relationship between attributes and calculate a relationship weighting. A high frequency of co-occurrence may indicate that the attributes provide distinct information and therefore should not be merged. However due to the skewed distribution of attribute usage, highly popular attributes will co-occur more frequently than less popular attributes. To account for frequency of use when calculating co-occurrence weighting the following normalisation is performed.


If $C(a_{1})$ is the number of occurrences of the first attribute, $C(a_{2})$ the number of occurrences of the second and $C(a_{t})$ the total occurrences of all attributes in the dataset. The probability of $C(a_{1})$ occurrence ($P_{(a1)}$) is:

$\displaystyle P_{(a1)} = \frac{C(a_{1})}{C(a_{t})}$

Therefore, we can calculate the expected co-occurrence ($E[x]$) if attributes were randomly paired:

$\displaystyle E[x] = P_{(a1)} \cdot P_{(a2)} \cdot P_{(t)}$

The observed co-occurrence ($O[x]$) for each pair is transformed into a normalised weight ($W_{(a1, a2)}$) like so:

$\displaystyle W_{(a1, a2)} = \frac{O[x] - E[x]}{\sum (O[x] - E[x])}$

These weights are used to create a NetworkX co-occurrence graph. If the frequency of co-occurrence is zero the weight will also be zero, although these edges are not explicitly calculated to reduce overhead. Equally the co-occurrence JSON only contains counts greater than zero. The theoretical weight range is +1 to -1 and all weights in the graph sum to 1. As the majority of BioSamples metadata records come from relatively few sources, downstream validation biases these weightings. For example, table \ref{table:pair_weights} a. shows the 5 strongest associated attributes which are all required in European Nucleotide Archive (ENA) checklists [REF]. Equally bias, table \ref{table:pair_weights} b. shows the weakest attribute associations [INSERT DESCRIPTION OF THESE HERE AFTER SPEAKING TO ENA]. Nevertheless, weights are often intuitively relevant. For example, table \ref{table:pair_weights} c. highlights three pairs that intuitively belong together (depth \& elevation, serovar \& strain and disease state \& individual) and two pairs that occupy contrary domains which intuitively don't overlap (organism part \& serovar and organism part \& environment biome). Individual attribute nodes are connected by the weights described above in a Neo4J subgraph (not connected to the graph layout shown in figure \ref{fig:workflow}) which powers the recommendation functionality in Curami.

\subsection*{Attribute Recommendation}

Due to the diverse nature of the BioSamples data set, slicing attributes by specialism is a very important curator requirement. Rather than predefining these slices the application allows the user to select attributes that are commonly associated with the dataset they are interested in, and uses this to suggest pairs that are relevant by looking at attributes that are closest according to the co-occurrence weighting. For example, a curator interested in marine metagenome samples could choose attributes [GIVE SOME SUGGESTIONS HERE THAT FIT WITH THE FIGURE]

% make a figure showing screenshots of the recommendation functionality


\subsection*{Calculated Data Features}

\subsection*{Different setting options}

\subsection*{Actual Curation Work (including some observations of problems and potential issues)}
\subsection*{Pair Sorting Settings} \label{pair_sorting_settings}

\section*{Results}

% Using the app how many pairs were typically curated in 10 minutes

%How many attributes
%Most frequent attributes
%distribution of attributes
%distribution of values

\section*{Discussion}

%Must describe rationale of pairings

Curami is designed to be used from two perspectives. As an assisted curation application it can be used to navigate the user through their domains of interest within the dataset and provide auxiliary information to the curator which may increase their confidence and allow them to make a curation decision. From a second perspective, this decision capture is incredibly useful as a training set to later discover in which circumstances the calculated features become predictive indicators of a required curation operation. Although this work has not explored analysis of the captured features, this second utility was a major contributing factor to the design of Curami. Displaying the right pairs to the curator and the information required to make decisions will aid the curation process [REF NEEDED] but the potential of later leveraging each of these decisions through machine learning will further increase a curators impact. However, the current lack of training data dictated that as a first step, Curami had to provide immediate utility whilst generating training data for later correlation analysis.

% NB \ref{table:pair_weights} a. has colection date spelled wrong which is worth pointing out in the discussion

% Need to address the lack of ontology work.

\section*{Conclusion}

% Further work. Looking for predictive features, especially orthogonal ones

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Backmatter begins here                   %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{backmatter}

\section*{Competing interests}
  The authors declare that they have no competing interests.

\section*{Author's contributions}
    Text for this section \ldots

\section*{Acknowledgements}
  Text for this section \ldots
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                  The Bibliography                       %%
%%                                                         %%
%%  Bmc_mathpys.bst  will be used to                       %%
%%  create a .BBL file for submission.                     %%
%%  After submission of the .TEX file,                     %%
%%  you will be prompted to submit your .BBL file.         %%
%%                                                         %%
%%                                                         %%
%%  Note that the displayed Bibliography will not          %%
%%  necessarily be rendered by Latex exactly as specified  %%
%%  in the online Instructions for Authors.                %%
%%                                                         %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% if your bibliography is in bibtex format, use those commands:
\bibliographystyle{bmc-mathphys} % Style BST file (bmc-mathphys, vancouver, spbasic).
\bibliography{bmc_article}      % Bibliography file (usually '*.bib' )
% for author-year bibliography (bmc-mathphys or spbasic)
% a) write to bib file (bmc-mathphys only)
% @settings{label, options="nameyear"}
% b) uncomment next line
%\nocite{label}

% or include bibliography directly:
% \begin{thebibliography}
% \bibitem{b1}
% \end{thebibliography}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                               %%
%% Figures                       %%
%%                               %%
%% NB: this is for captions and  %%
%% Titles. All graphics must be  %%
%% submitted separately and NOT  %%
%% included in the Tex document  %%
%%                               %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%
%% Do not use \listoffigures as most will included as separate files

\section*{Figures}
  \begin{figure}[h!]
  \caption{\csentence{Data and Work Flow}
      Overview of the modular design of Curami showing separation of modules and general dataflow. Initialization and analysis modules 1-5 should be executed in series to pull information from the BioSamples API to generate input files, pair lexically similar attributes, extract pairwise and individual features and store the results in the Neo4J database. The Data Analysis Store has three node types User, Pair and Attribute with corresponding relationships as shown. Edges \textit{r1} represent curation decisions made by the user about a pair of attributes and can be one of four types; merge, merge with reversed polarity, don't merge and skip. Edged \textit{r2} has only one type, 'pair contains', and indicated which individual attributes are in the pair. The Curation Interface allows curators to view the attribute pairs sorted by applying one of the available settings described in section \ref{pair_sorting_settings}. Curation decisions are then stored in the Neo4J database which can then be directly converted into curation objects, a format that can be directly submitted to the BioSamples API.}
\label{fig:workflow}
\end{figure}

  \begin{figure}[h!]
  \caption{\csentence{Gephi snapshot} 
  Snapshot from the interactive network layout tool Gephi \cite{bastian2009gephi}. Each attribute is a node and the node size represents the approximate frequency of attribute usage (size is binned rather than scaled). The Fruchterman-Reingold layout \cite{fruchterman1991graph} uses cooccurance weighting captured on the edges which are represented as grey lines between nodes. Colour assignment was done using the inbuilt Newman's modularity function \cite{newman2006modularity} to loosely highlight node clusters. Some specific attributes  are labelled along with some large clusters that show many attributes related to 'human metagenome' samples and a commonly used 'medical screen'.
  }
\label{fig:gephi}
\end{figure}

%\begin{figure}[h!]
%  \caption{\csentence{Sample figure title.}
%      Figure legend text.}
%      \end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                               %%
%% Tables                        %%
%%                               %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% Use of \listoftables is discouraged.
%%
\section*{Tables}
\begin{table}[h!]
\caption{A table of analysis features calculated for each attribute pair.}
      \begin{tabular}{|p{3cm}|p{10cm}|}
        \hline
           Feature & Description  \\ \hline
           Levenshtein Distance &  \cite{levenshtein1966binary}. N.B. pairs that score < 0.8 are not included. \\
           Attribute 1 frequency & The frequency of usage of attribute 1. This is used to predict the polarity of the merge. This assumes that the most popular attribute is most likely to be correct. \\
           Attribute 2 frequency & The frequency of usage of attribute 2.  \\
           Discrepancy Type & The result of several lexical tests (see table \ref{table:lexical_catagorisation}) \\
           Camel Case & Boolean indicating lexical detection of potential camel case usage. \\
           Edge Weight & placeholder \\
           Jaccard Coefficient \cite{jaccard1901distribution} & Calculated using the co-occurrence NetworkX graph. Quantifies the overlap of usage between attributes which may not directly co-occur (have a weighted edge in the graph). \\
           Break Number & placeholder \\
           Degree & placeholder \\
           Edge Total & placeholder \\
           Value Match Type & Can be either numeric, date or string match if more than 90\% of the values adhere to one data type. Alternatively, the field will show a mixed match or no match. \\
           Order of Magnitude & placeholder \\
           Jaro Score & placeholder \\ \hline
      \end{tabular}
\label{table:features}
\end{table}

\begin{table}[h!]
\caption{These tests aim to catagorize the lexical difference between the lexically similar attributes. $^\ddagger$ are strong candidates for automated curation.}
      \begin{tabular}{|p{3.5cm}|p{9.5cm}|}
        \hline
        Lexical Catagory & Description of Difference Test  \\ \hline
        Number Discrepancy & A numerical character differentiates the attributes. \\
        Case Discrepancy & If case stripping improves the Levenshtein score, case is identified as at least one differential factor. \\
        Space Discrepancy & Indicates if a space is at least one part of the discrepancy. \\
        Only Space Discrepancy$^\ddagger$  & If a space difference is the only difference between the attributes. \\
        Specials Discrepancy & If special characters are partially responsible for the difference. \\
        Just Specials Discrepancy$^\ddagger$ & If special characters are the only difference between the attributes. \\
        Word Number Discrepancy & If the number of tokens in the attributes differ. \\
        Stop Word Discrepancy & If the difference is due to the presence of stopwords (from the NLTK corpus imported from nltk.corpus import stopwords).  \\
        Dictionary Matching & Triggered if there is a difference in spelling between the attribute's tokens (so ignoring equally misspelled tokens) that fail a dictionary test against enchants US dictionary after stripping numbers, case and special characters. \\
        Lemmatisation Matching &  If lemmatisation or stemming produces an identical match. \\
        S discrepancy$^\ddagger$  & If an additional 's' character is the only difference between attributes. \\

           \hline
      \end{tabular}
\label{table:lexical_catagorisation}
\end{table}

% Note that space discrepancies will not be calculated if camel cased attributes are detected.
% dictionary not currently supplemented but could be in the future: supplemented with a large custom dictionary created using labels from all the ontologies captured via https://www.ebi.ac.uk/rdf.
% Lemmatisation and stemming are similar processes that strip a word back to its core. This is intended to find issues such as pluralisation or e.g. geographical vs geographically. If the only difference between facets is the addition of an 's' to the end of one of the tokens this is recorded separately with the test s_discrepancy and a slight variation sLower_discrepancy. In the latter, the only difference is the 's' ending and case differences. These are very good candidates for automated curation.


\begin{table}[h!]
\caption{a. Most strongly associated and b. weakly associated pairs ranked by co-occurrence weighting. c. Highlights pairs that demonstrate intuitive validation of the weighted ranking.}
      \begin{tabular}{|p{1cm}|p{3.5cm}|p{3.5cm}|p{2.5cm}|}

        \multicolumn{2}{l}{\textbf{a. Strongest attribute associations}}  \\ \hline
        Rank & Attribute Name & Second Attribute Name & $W_{(a1, a2)}$  \\ \hline
	1 & package & synonym & \num{6.94e-04} \\
	2 & model & synonym & \num{6.94e-04} \\
	3 & colection date & geographic location & \num{4.45e-04} \\
        4 & geographic location & package & \num{4.43e-04} \\
        5 & geographic location & model & \num{4.43e-04} \\ \hline
        
        \multicolumn{2}{l}{} \\
        
         \multicolumn{2}{l}{\textbf{b. Weakest attribute associations }}  \\ \hline
        Rank & Attribute Name & Second Attribute Name & $W_{(a1, a2)}$  \\ \hline
	710293 & Sample source name & synonym & \num{-2.54e-04} \\
	710294 & Sample\_source\_name & model & \num{-2.87e-04} \\
	710295 & description & model & \num{-4.06e-04} \\
        710296 & description & package & \num{-4.07e-04} \\
        710297 & Sample\_source\_name & synonym & \num{-4.17e-04} \\ \hline
        
         \multicolumn{2}{l}{} \\
        
         \multicolumn{2}{l}{\textbf{c. Highlighted pairs}}  \\ \hline
        Rank & Attribute Name & Second Attribute Name & $W_{(a1, a2)}$  \\ \hline
        107 & depth & elevation & \num{8.72e-05} \\
         251 & serovar & strain & \num{5.90e-05} \\
         363 & disease state & individual & \num{4.84e-05} \\
	710117 & organism part & serovar & \num{-2.38e-05} \\
	710223 & environment biome & organism part & \num{-5.24e-05} \\
	
	
	


 \hline
        
      \end{tabular}

      
\label{table:pair_weights}
\end{table}

%These negative weights are often intuitively relevant (e.g. organism part and serovar with a difference of -27689 (weight -2.38e-05) or environment biome and organism part with a difference of -89490 (weight -5.24e-05)) and highly positive weights are also intuitive (e.g. depth and elevation with a difference of 99617 (weight 8.72e-05)).




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                               %%
%% Additional Files              %%
%%                               %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\section*{Additional Files}
%  \subsection*{Additional file 1 --- Sample additional file title}
%    Additional file descriptions text (including details of how to
%    view the file, if it is in a non-standard format or the file extension).  This might
%    refer to a multi-page table or a figure.

%  \subsection*{Additional file 2 --- Sample additional file title}
%    Additional file descriptions text.


\end{backmatter}
\end{document}
